name: "mxnet-mdoel"
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape: { dim: 10 dim: 3 dim: 224 dim: 224 }
  }
}

layer {
	bottom: "data"
	top: "conv1_x_1__conv"
	name: "conv1_x_1__conv"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 7
		pad: 3
		group: 1
		stride: 2
		bias_term: false
	}
	param {
	  name: "data"
	}
}

layer {
  bottom: "conv1_x_1__conv"
  top: "conv1_x_1__relu-sp__bn"
  name: "conv1_x_1__relu-sp__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv1_x_1__relu-sp__bn"
  top: "conv1_x_1__relu-sp__bn"
  name: "conv1_x_1__relu-sp__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv1_x_1__relu-sp__bn"
  top: "conv1_x_1__relu-sp__relu"
  name: "conv1_x_1__relu-sp__relu"
  type: "ReLU"
}

layer {
  bottom: "conv1_x_1__relu-sp__relu"
  top: "pool1"
  name: "pool1"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}

layer {
  bottom: "pool1"
  top: "conv2_x__1_c1x1-w(s/1)__bn__bn"
  name: "conv2_x__1_c1x1-w(s/1)__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv2_x__1_c1x1-w(s/1)__bn__bn"
  top: "conv2_x__1_c1x1-w(s/1)__bn__bn"
  name: "conv2_x__1_c1x1-w(s/1)__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv2_x__1_c1x1-w(s/1)__bn__bn"
  top: "conv2_x__1_c1x1-w(s/1)__ac__relu"
  name: "conv2_x__1_c1x1-w(s/1)__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv2_x__1_c1x1-w(s/1)__ac__relu"
	top: "conv2_x__1_c1x1-w(s/1)__conv"
	name: "conv2_x__1_c1x1-w(s/1)__conv"
	type: "Convolution"
	convolution_param {
		num_output: 288
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '256', 'begin': '0'}, 'top': 'conv2_x__1_c1x1-w(s/1)-split1', 'name': 'conv2_x__1_c1x1-w(s/1)-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[13, 0]], 'backward_source_id': -1, 'bottom': ['conv2_x__1_c1x1-w(s/1)__conv']}
</slice_json>
layer {
  bottom: "pool1"
  top: "conv2_x__1_c1x1-a__bn__bn"
  name: "conv2_x__1_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv2_x__1_c1x1-a__bn__bn"
  top: "conv2_x__1_c1x1-a__bn__bn"
  name: "conv2_x__1_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv2_x__1_c1x1-a__bn__bn"
  top: "conv2_x__1_c1x1-a__ac__relu"
  name: "conv2_x__1_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv2_x__1_c1x1-a__ac__relu"
	top: "conv2_x__1_c1x1-a__conv"
	name: "conv2_x__1_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 96
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv2_x__1_c1x1-a__conv"
  top: "conv2_x__1_c3x3-b__bn__bn"
  name: "conv2_x__1_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv2_x__1_c3x3-b__bn__bn"
  top: "conv2_x__1_c3x3-b__bn__bn"
  name: "conv2_x__1_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv2_x__1_c3x3-b__bn__bn"
  top: "conv2_x__1_c3x3-b__ac__relu"
  name: "conv2_x__1_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv2_x__1_c3x3-b__ac__relu"
	top: "conv2_x__1_c3x3-b__conv"
	name: "conv2_x__1_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 96
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv2_x__1_c3x3-b__conv"
  top: "conv2_x__1_c1x1-c__bn__bn"
  name: "conv2_x__1_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv2_x__1_c1x1-c__bn__bn"
  top: "conv2_x__1_c1x1-c__bn__bn"
  name: "conv2_x__1_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv2_x__1_c1x1-c__bn__bn"
  top: "conv2_x__1_c1x1-c__ac__relu"
  name: "conv2_x__1_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv2_x__1_c1x1-c__ac__relu"
	top: "conv2_x__1_c1x1-c__conv"
	name: "conv2_x__1_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 272
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '256', 'begin': '0'}, 'top': 'conv2_x__1_c1x1-c-split1', 'name': 'conv2_x__1_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[32, 0]], 'backward_source_id': -1, 'bottom': ['conv2_x__1_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv2_x__1_sum"
  type: "Eltwise"
  bottom: "conv2_x__1_c1x1-w(s/1)-split1"
  bottom: "conv2_x__1_c1x1-c-split1"
  top: "conv2_x__1_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '288', 'begin': '256'}, 'top': 'conv2_x__1_c1x1-w(s/1)-split2', 'name': 'conv2_x__1_c1x1-w(s/1)-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[13, 0]], 'backward_source_id': -1, 'bottom': ['conv2_x__1_c1x1-w(s/1)__conv']}
</slice_json>
<slice_json>
{'param': {'axis': '1', 'end': '272', 'begin': '256'}, 'top': 'conv2_x__1_c1x1-c-split2', 'name': 'conv2_x__1_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[32, 0]], 'backward_source_id': -1, 'bottom': ['conv2_x__1_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv2_x__1_cat"
  type: "Concat"
  bottom: "conv2_x__1_c1x1-w(s/1)-split2"
  bottom: "conv2_x__1_c1x1-c-split2"
  top: "conv2_x__1_cat"
}

layer {
  name: "conv2_x__2_cat-input"
  type: "Concat"
  bottom: "conv2_x__1_sum"
  bottom: "conv2_x__1_cat"
  top: "conv2_x__2_cat-input"
}

layer {
  bottom: "conv2_x__2_cat-input"
  top: "conv2_x__2_c1x1-a__bn__bn"
  name: "conv2_x__2_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv2_x__2_c1x1-a__bn__bn"
  top: "conv2_x__2_c1x1-a__bn__bn"
  name: "conv2_x__2_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv2_x__2_c1x1-a__bn__bn"
  top: "conv2_x__2_c1x1-a__ac__relu"
  name: "conv2_x__2_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv2_x__2_c1x1-a__ac__relu"
	top: "conv2_x__2_c1x1-a__conv"
	name: "conv2_x__2_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 96
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv2_x__2_c1x1-a__conv"
  top: "conv2_x__2_c3x3-b__bn__bn"
  name: "conv2_x__2_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv2_x__2_c3x3-b__bn__bn"
  top: "conv2_x__2_c3x3-b__bn__bn"
  name: "conv2_x__2_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv2_x__2_c3x3-b__bn__bn"
  top: "conv2_x__2_c3x3-b__ac__relu"
  name: "conv2_x__2_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv2_x__2_c3x3-b__ac__relu"
	top: "conv2_x__2_c3x3-b__conv"
	name: "conv2_x__2_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 96
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv2_x__2_c3x3-b__conv"
  top: "conv2_x__2_c1x1-c__bn__bn"
  name: "conv2_x__2_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv2_x__2_c1x1-c__bn__bn"
  top: "conv2_x__2_c1x1-c__bn__bn"
  name: "conv2_x__2_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv2_x__2_c1x1-c__bn__bn"
  top: "conv2_x__2_c1x1-c__ac__relu"
  name: "conv2_x__2_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv2_x__2_c1x1-c__ac__relu"
	top: "conv2_x__2_c1x1-c__conv"
	name: "conv2_x__2_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 272
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '256', 'begin': '0'}, 'top': 'conv2_x__2_c1x1-c-split1', 'name': 'conv2_x__2_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[56, 0]], 'backward_source_id': -1, 'bottom': ['conv2_x__2_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv2_x__2_sum"
  type: "Eltwise"
  bottom: "conv2_x__1_sum"
  bottom: "conv2_x__2_c1x1-c-split1"
  top: "conv2_x__2_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '272', 'begin': '256'}, 'top': 'conv2_x__2_c1x1-c-split2', 'name': 'conv2_x__2_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[56, 0]], 'backward_source_id': -1, 'bottom': ['conv2_x__2_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv2_x__2_cat"
  type: "Concat"
  bottom: "conv2_x__1_cat"
  bottom: "conv2_x__2_c1x1-c-split2"
  top: "conv2_x__2_cat"
}

layer {
  name: "conv2_x__3_cat-input"
  type: "Concat"
  bottom: "conv2_x__2_sum"
  bottom: "conv2_x__2_cat"
  top: "conv2_x__3_cat-input"
}

layer {
  bottom: "conv2_x__3_cat-input"
  top: "conv2_x__3_c1x1-a__bn__bn"
  name: "conv2_x__3_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv2_x__3_c1x1-a__bn__bn"
  top: "conv2_x__3_c1x1-a__bn__bn"
  name: "conv2_x__3_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv2_x__3_c1x1-a__bn__bn"
  top: "conv2_x__3_c1x1-a__ac__relu"
  name: "conv2_x__3_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv2_x__3_c1x1-a__ac__relu"
	top: "conv2_x__3_c1x1-a__conv"
	name: "conv2_x__3_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 96
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv2_x__3_c1x1-a__conv"
  top: "conv2_x__3_c3x3-b__bn__bn"
  name: "conv2_x__3_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv2_x__3_c3x3-b__bn__bn"
  top: "conv2_x__3_c3x3-b__bn__bn"
  name: "conv2_x__3_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv2_x__3_c3x3-b__bn__bn"
  top: "conv2_x__3_c3x3-b__ac__relu"
  name: "conv2_x__3_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv2_x__3_c3x3-b__ac__relu"
	top: "conv2_x__3_c3x3-b__conv"
	name: "conv2_x__3_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 96
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv2_x__3_c3x3-b__conv"
  top: "conv2_x__3_c1x1-c__bn__bn"
  name: "conv2_x__3_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv2_x__3_c1x1-c__bn__bn"
  top: "conv2_x__3_c1x1-c__bn__bn"
  name: "conv2_x__3_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv2_x__3_c1x1-c__bn__bn"
  top: "conv2_x__3_c1x1-c__ac__relu"
  name: "conv2_x__3_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv2_x__3_c1x1-c__ac__relu"
	top: "conv2_x__3_c1x1-c__conv"
	name: "conv2_x__3_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 272
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '256', 'begin': '0'}, 'top': 'conv2_x__3_c1x1-c-split1', 'name': 'conv2_x__3_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[79, 0]], 'backward_source_id': -1, 'bottom': ['conv2_x__3_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv2_x__3_sum"
  type: "Eltwise"
  bottom: "conv2_x__2_sum"
  bottom: "conv2_x__3_c1x1-c-split1"
  top: "conv2_x__3_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '272', 'begin': '256'}, 'top': 'conv2_x__3_c1x1-c-split2', 'name': 'conv2_x__3_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[79, 0]], 'backward_source_id': -1, 'bottom': ['conv2_x__3_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv2_x__3_cat"
  type: "Concat"
  bottom: "conv2_x__2_cat"
  bottom: "conv2_x__3_c1x1-c-split2"
  top: "conv2_x__3_cat"
}

layer {
  name: "conv3_x__1_cat-input"
  type: "Concat"
  bottom: "conv2_x__3_sum"
  bottom: "conv2_x__3_cat"
  top: "conv3_x__1_cat-input"
}

layer {
  bottom: "conv3_x__1_cat-input"
  top: "conv3_x__1_c1x1-w(s/2)__bn__bn"
  name: "conv3_x__1_c1x1-w(s/2)__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv3_x__1_c1x1-w(s/2)__bn__bn"
  top: "conv3_x__1_c1x1-w(s/2)__bn__bn"
  name: "conv3_x__1_c1x1-w(s/2)__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv3_x__1_c1x1-w(s/2)__bn__bn"
  top: "conv3_x__1_c1x1-w(s/2)__ac__relu"
  name: "conv3_x__1_c1x1-w(s/2)__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv3_x__1_c1x1-w(s/2)__ac__relu"
	top: "conv3_x__1_c1x1-w(s/2)__conv"
	name: "conv3_x__1_c1x1-w(s/2)__conv"
	type: "Convolution"
	convolution_param {
		num_output: 576
		kernel_size: 1
		pad: 0
		group: 1
		stride: 2
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '512', 'begin': '0'}, 'top': 'conv3_x__1_c1x1-w(s/2)-split1', 'name': 'conv3_x__1_c1x1-w(s/2)-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[90, 0]], 'backward_source_id': -1, 'bottom': ['conv3_x__1_c1x1-w(s/2)__conv']}
</slice_json>
layer {
  bottom: "conv3_x__1_cat-input"
  top: "conv3_x__1_c1x1-a__bn__bn"
  name: "conv3_x__1_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv3_x__1_c1x1-a__bn__bn"
  top: "conv3_x__1_c1x1-a__bn__bn"
  name: "conv3_x__1_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv3_x__1_c1x1-a__bn__bn"
  top: "conv3_x__1_c1x1-a__ac__relu"
  name: "conv3_x__1_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv3_x__1_c1x1-a__ac__relu"
	top: "conv3_x__1_c1x1-a__conv"
	name: "conv3_x__1_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 192
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv3_x__1_c1x1-a__conv"
  top: "conv3_x__1_c3x3-b__bn__bn"
  name: "conv3_x__1_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv3_x__1_c3x3-b__bn__bn"
  top: "conv3_x__1_c3x3-b__bn__bn"
  name: "conv3_x__1_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv3_x__1_c3x3-b__bn__bn"
  top: "conv3_x__1_c3x3-b__ac__relu"
  name: "conv3_x__1_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv3_x__1_c3x3-b__ac__relu"
	top: "conv3_x__1_c3x3-b__conv"
	name: "conv3_x__1_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 192
		kernel_size: 3
		pad: 1
		group: 32
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "conv3_x__1_c3x3-b__conv"
  top: "conv3_x__1_c1x1-c__bn__bn"
  name: "conv3_x__1_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv3_x__1_c1x1-c__bn__bn"
  top: "conv3_x__1_c1x1-c__bn__bn"
  name: "conv3_x__1_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv3_x__1_c1x1-c__bn__bn"
  top: "conv3_x__1_c1x1-c__ac__relu"
  name: "conv3_x__1_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv3_x__1_c1x1-c__ac__relu"
	top: "conv3_x__1_c1x1-c__conv"
	name: "conv3_x__1_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 544
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '512', 'begin': '0'}, 'top': 'conv3_x__1_c1x1-c-split1', 'name': 'conv3_x__1_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[109, 0]], 'backward_source_id': -1, 'bottom': ['conv3_x__1_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv3_x__1_sum"
  type: "Eltwise"
  bottom: "conv3_x__1_c1x1-w(s/2)-split1"
  bottom: "conv3_x__1_c1x1-c-split1"
  top: "conv3_x__1_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '576', 'begin': '512'}, 'top': 'conv3_x__1_c1x1-w(s/2)-split2', 'name': 'conv3_x__1_c1x1-w(s/2)-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[90, 0]], 'backward_source_id': -1, 'bottom': ['conv3_x__1_c1x1-w(s/2)__conv']}
</slice_json>
<slice_json>
{'param': {'axis': '1', 'end': '544', 'begin': '512'}, 'top': 'conv3_x__1_c1x1-c-split2', 'name': 'conv3_x__1_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[109, 0]], 'backward_source_id': -1, 'bottom': ['conv3_x__1_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv3_x__1_cat"
  type: "Concat"
  bottom: "conv3_x__1_c1x1-w(s/2)-split2"
  bottom: "conv3_x__1_c1x1-c-split2"
  top: "conv3_x__1_cat"
}

layer {
  name: "conv3_x__2_cat-input"
  type: "Concat"
  bottom: "conv3_x__1_sum"
  bottom: "conv3_x__1_cat"
  top: "conv3_x__2_cat-input"
}

layer {
  bottom: "conv3_x__2_cat-input"
  top: "conv3_x__2_c1x1-a__bn__bn"
  name: "conv3_x__2_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv3_x__2_c1x1-a__bn__bn"
  top: "conv3_x__2_c1x1-a__bn__bn"
  name: "conv3_x__2_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv3_x__2_c1x1-a__bn__bn"
  top: "conv3_x__2_c1x1-a__ac__relu"
  name: "conv3_x__2_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv3_x__2_c1x1-a__ac__relu"
	top: "conv3_x__2_c1x1-a__conv"
	name: "conv3_x__2_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 192
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv3_x__2_c1x1-a__conv"
  top: "conv3_x__2_c3x3-b__bn__bn"
  name: "conv3_x__2_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv3_x__2_c3x3-b__bn__bn"
  top: "conv3_x__2_c3x3-b__bn__bn"
  name: "conv3_x__2_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv3_x__2_c3x3-b__bn__bn"
  top: "conv3_x__2_c3x3-b__ac__relu"
  name: "conv3_x__2_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv3_x__2_c3x3-b__ac__relu"
	top: "conv3_x__2_c3x3-b__conv"
	name: "conv3_x__2_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 192
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv3_x__2_c3x3-b__conv"
  top: "conv3_x__2_c1x1-c__bn__bn"
  name: "conv3_x__2_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv3_x__2_c1x1-c__bn__bn"
  top: "conv3_x__2_c1x1-c__bn__bn"
  name: "conv3_x__2_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv3_x__2_c1x1-c__bn__bn"
  top: "conv3_x__2_c1x1-c__ac__relu"
  name: "conv3_x__2_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv3_x__2_c1x1-c__ac__relu"
	top: "conv3_x__2_c1x1-c__conv"
	name: "conv3_x__2_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 544
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '512', 'begin': '0'}, 'top': 'conv3_x__2_c1x1-c-split1', 'name': 'conv3_x__2_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[133, 0]], 'backward_source_id': -1, 'bottom': ['conv3_x__2_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv3_x__2_sum"
  type: "Eltwise"
  bottom: "conv3_x__1_sum"
  bottom: "conv3_x__2_c1x1-c-split1"
  top: "conv3_x__2_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '544', 'begin': '512'}, 'top': 'conv3_x__2_c1x1-c-split2', 'name': 'conv3_x__2_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[133, 0]], 'backward_source_id': -1, 'bottom': ['conv3_x__2_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv3_x__2_cat"
  type: "Concat"
  bottom: "conv3_x__1_cat"
  bottom: "conv3_x__2_c1x1-c-split2"
  top: "conv3_x__2_cat"
}

layer {
  name: "conv3_x__3_cat-input"
  type: "Concat"
  bottom: "conv3_x__2_sum"
  bottom: "conv3_x__2_cat"
  top: "conv3_x__3_cat-input"
}

layer {
  bottom: "conv3_x__3_cat-input"
  top: "conv3_x__3_c1x1-a__bn__bn"
  name: "conv3_x__3_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv3_x__3_c1x1-a__bn__bn"
  top: "conv3_x__3_c1x1-a__bn__bn"
  name: "conv3_x__3_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv3_x__3_c1x1-a__bn__bn"
  top: "conv3_x__3_c1x1-a__ac__relu"
  name: "conv3_x__3_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv3_x__3_c1x1-a__ac__relu"
	top: "conv3_x__3_c1x1-a__conv"
	name: "conv3_x__3_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 192
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv3_x__3_c1x1-a__conv"
  top: "conv3_x__3_c3x3-b__bn__bn"
  name: "conv3_x__3_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv3_x__3_c3x3-b__bn__bn"
  top: "conv3_x__3_c3x3-b__bn__bn"
  name: "conv3_x__3_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv3_x__3_c3x3-b__bn__bn"
  top: "conv3_x__3_c3x3-b__ac__relu"
  name: "conv3_x__3_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv3_x__3_c3x3-b__ac__relu"
	top: "conv3_x__3_c3x3-b__conv"
	name: "conv3_x__3_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 192
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv3_x__3_c3x3-b__conv"
  top: "conv3_x__3_c1x1-c__bn__bn"
  name: "conv3_x__3_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv3_x__3_c1x1-c__bn__bn"
  top: "conv3_x__3_c1x1-c__bn__bn"
  name: "conv3_x__3_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv3_x__3_c1x1-c__bn__bn"
  top: "conv3_x__3_c1x1-c__ac__relu"
  name: "conv3_x__3_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv3_x__3_c1x1-c__ac__relu"
	top: "conv3_x__3_c1x1-c__conv"
	name: "conv3_x__3_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 544
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '512', 'begin': '0'}, 'top': 'conv3_x__3_c1x1-c-split1', 'name': 'conv3_x__3_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[156, 0]], 'backward_source_id': -1, 'bottom': ['conv3_x__3_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv3_x__3_sum"
  type: "Eltwise"
  bottom: "conv3_x__2_sum"
  bottom: "conv3_x__3_c1x1-c-split1"
  top: "conv3_x__3_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '544', 'begin': '512'}, 'top': 'conv3_x__3_c1x1-c-split2', 'name': 'conv3_x__3_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[156, 0]], 'backward_source_id': -1, 'bottom': ['conv3_x__3_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv3_x__3_cat"
  type: "Concat"
  bottom: "conv3_x__2_cat"
  bottom: "conv3_x__3_c1x1-c-split2"
  top: "conv3_x__3_cat"
}

layer {
  name: "conv3_x__4_cat-input"
  type: "Concat"
  bottom: "conv3_x__3_sum"
  bottom: "conv3_x__3_cat"
  top: "conv3_x__4_cat-input"
}

layer {
  bottom: "conv3_x__4_cat-input"
  top: "conv3_x__4_c1x1-a__bn__bn"
  name: "conv3_x__4_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv3_x__4_c1x1-a__bn__bn"
  top: "conv3_x__4_c1x1-a__bn__bn"
  name: "conv3_x__4_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv3_x__4_c1x1-a__bn__bn"
  top: "conv3_x__4_c1x1-a__ac__relu"
  name: "conv3_x__4_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv3_x__4_c1x1-a__ac__relu"
	top: "conv3_x__4_c1x1-a__conv"
	name: "conv3_x__4_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 192
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv3_x__4_c1x1-a__conv"
  top: "conv3_x__4_c3x3-b__bn__bn"
  name: "conv3_x__4_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv3_x__4_c3x3-b__bn__bn"
  top: "conv3_x__4_c3x3-b__bn__bn"
  name: "conv3_x__4_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv3_x__4_c3x3-b__bn__bn"
  top: "conv3_x__4_c3x3-b__ac__relu"
  name: "conv3_x__4_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv3_x__4_c3x3-b__ac__relu"
	top: "conv3_x__4_c3x3-b__conv"
	name: "conv3_x__4_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 192
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv3_x__4_c3x3-b__conv"
  top: "conv3_x__4_c1x1-c__bn__bn"
  name: "conv3_x__4_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv3_x__4_c1x1-c__bn__bn"
  top: "conv3_x__4_c1x1-c__bn__bn"
  name: "conv3_x__4_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv3_x__4_c1x1-c__bn__bn"
  top: "conv3_x__4_c1x1-c__ac__relu"
  name: "conv3_x__4_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv3_x__4_c1x1-c__ac__relu"
	top: "conv3_x__4_c1x1-c__conv"
	name: "conv3_x__4_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 544
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '512', 'begin': '0'}, 'top': 'conv3_x__4_c1x1-c-split1', 'name': 'conv3_x__4_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[179, 0]], 'backward_source_id': -1, 'bottom': ['conv3_x__4_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv3_x__4_sum"
  type: "Eltwise"
  bottom: "conv3_x__3_sum"
  bottom: "conv3_x__4_c1x1-c-split1"
  top: "conv3_x__4_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '544', 'begin': '512'}, 'top': 'conv3_x__4_c1x1-c-split2', 'name': 'conv3_x__4_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[179, 0]], 'backward_source_id': -1, 'bottom': ['conv3_x__4_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv3_x__4_cat"
  type: "Concat"
  bottom: "conv3_x__3_cat"
  bottom: "conv3_x__4_c1x1-c-split2"
  top: "conv3_x__4_cat"
}

layer {
  name: "conv4_x__1_cat-input"
  type: "Concat"
  bottom: "conv3_x__4_sum"
  bottom: "conv3_x__4_cat"
  top: "conv4_x__1_cat-input"
}

layer {
  bottom: "conv4_x__1_cat-input"
  top: "conv4_x__1_c1x1-w(s/2)__bn__bn"
  name: "conv4_x__1_c1x1-w(s/2)__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__1_c1x1-w(s/2)__bn__bn"
  top: "conv4_x__1_c1x1-w(s/2)__bn__bn"
  name: "conv4_x__1_c1x1-w(s/2)__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__1_c1x1-w(s/2)__bn__bn"
  top: "conv4_x__1_c1x1-w(s/2)__ac__relu"
  name: "conv4_x__1_c1x1-w(s/2)__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__1_c1x1-w(s/2)__ac__relu"
	top: "conv4_x__1_c1x1-w(s/2)__conv"
	name: "conv4_x__1_c1x1-w(s/2)__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1072
		kernel_size: 1
		pad: 0
		group: 1
		stride: 2
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__1_c1x1-w(s/2)-split1', 'name': 'conv4_x__1_c1x1-w(s/2)-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[190, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__1_c1x1-w(s/2)__conv']}
</slice_json>
layer {
  bottom: "conv4_x__1_cat-input"
  top: "conv4_x__1_c1x1-a__bn__bn"
  name: "conv4_x__1_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__1_c1x1-a__bn__bn"
  top: "conv4_x__1_c1x1-a__bn__bn"
  name: "conv4_x__1_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__1_c1x1-a__bn__bn"
  top: "conv4_x__1_c1x1-a__ac__relu"
  name: "conv4_x__1_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__1_c1x1-a__ac__relu"
	top: "conv4_x__1_c1x1-a__conv"
	name: "conv4_x__1_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__1_c1x1-a__conv"
  top: "conv4_x__1_c3x3-b__bn__bn"
  name: "conv4_x__1_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__1_c3x3-b__bn__bn"
  top: "conv4_x__1_c3x3-b__bn__bn"
  name: "conv4_x__1_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__1_c3x3-b__bn__bn"
  top: "conv4_x__1_c3x3-b__ac__relu"
  name: "conv4_x__1_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__1_c3x3-b__ac__relu"
	top: "conv4_x__1_c3x3-b__conv"
	name: "conv4_x__1_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__1_c3x3-b__conv"
  top: "conv4_x__1_c1x1-c__bn__bn"
  name: "conv4_x__1_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__1_c1x1-c__bn__bn"
  top: "conv4_x__1_c1x1-c__bn__bn"
  name: "conv4_x__1_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__1_c1x1-c__bn__bn"
  top: "conv4_x__1_c1x1-c__ac__relu"
  name: "conv4_x__1_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__1_c1x1-c__ac__relu"
	top: "conv4_x__1_c1x1-c__conv"
	name: "conv4_x__1_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__1_c1x1-c-split1', 'name': 'conv4_x__1_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[209, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__1_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__1_sum"
  type: "Eltwise"
  bottom: "conv4_x__1_c1x1-w(s/2)-split1"
  bottom: "conv4_x__1_c1x1-c-split1"
  top: "conv4_x__1_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1072', 'begin': '1024'}, 'top': 'conv4_x__1_c1x1-w(s/2)-split2', 'name': 'conv4_x__1_c1x1-w(s/2)-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[190, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__1_c1x1-w(s/2)__conv']}
</slice_json>
<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__1_c1x1-c-split2', 'name': 'conv4_x__1_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[209, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__1_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__1_cat"
  type: "Concat"
  bottom: "conv4_x__1_c1x1-w(s/2)-split2"
  bottom: "conv4_x__1_c1x1-c-split2"
  top: "conv4_x__1_cat"
}

layer {
  name: "conv4_x__2_cat-input"
  type: "Concat"
  bottom: "conv4_x__1_sum"
  bottom: "conv4_x__1_cat"
  top: "conv4_x__2_cat-input"
}

layer {
  bottom: "conv4_x__2_cat-input"
  top: "conv4_x__2_c1x1-a__bn__bn"
  name: "conv4_x__2_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__2_c1x1-a__bn__bn"
  top: "conv4_x__2_c1x1-a__bn__bn"
  name: "conv4_x__2_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__2_c1x1-a__bn__bn"
  top: "conv4_x__2_c1x1-a__ac__relu"
  name: "conv4_x__2_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__2_c1x1-a__ac__relu"
	top: "conv4_x__2_c1x1-a__conv"
	name: "conv4_x__2_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__2_c1x1-a__conv"
  top: "conv4_x__2_c3x3-b__bn__bn"
  name: "conv4_x__2_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__2_c3x3-b__bn__bn"
  top: "conv4_x__2_c3x3-b__bn__bn"
  name: "conv4_x__2_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__2_c3x3-b__bn__bn"
  top: "conv4_x__2_c3x3-b__ac__relu"
  name: "conv4_x__2_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__2_c3x3-b__ac__relu"
	top: "conv4_x__2_c3x3-b__conv"
	name: "conv4_x__2_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__2_c3x3-b__conv"
  top: "conv4_x__2_c1x1-c__bn__bn"
  name: "conv4_x__2_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__2_c1x1-c__bn__bn"
  top: "conv4_x__2_c1x1-c__bn__bn"
  name: "conv4_x__2_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__2_c1x1-c__bn__bn"
  top: "conv4_x__2_c1x1-c__ac__relu"
  name: "conv4_x__2_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__2_c1x1-c__ac__relu"
	top: "conv4_x__2_c1x1-c__conv"
	name: "conv4_x__2_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__2_c1x1-c-split1', 'name': 'conv4_x__2_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[233, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__2_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__2_sum"
  type: "Eltwise"
  bottom: "conv4_x__1_sum"
  bottom: "conv4_x__2_c1x1-c-split1"
  top: "conv4_x__2_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__2_c1x1-c-split2', 'name': 'conv4_x__2_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[233, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__2_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__2_cat"
  type: "Concat"
  bottom: "conv4_x__1_cat"
  bottom: "conv4_x__2_c1x1-c-split2"
  top: "conv4_x__2_cat"
}

layer {
  name: "conv4_x__3_cat-input"
  type: "Concat"
  bottom: "conv4_x__2_sum"
  bottom: "conv4_x__2_cat"
  top: "conv4_x__3_cat-input"
}

layer {
  bottom: "conv4_x__3_cat-input"
  top: "conv4_x__3_c1x1-a__bn__bn"
  name: "conv4_x__3_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__3_c1x1-a__bn__bn"
  top: "conv4_x__3_c1x1-a__bn__bn"
  name: "conv4_x__3_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__3_c1x1-a__bn__bn"
  top: "conv4_x__3_c1x1-a__ac__relu"
  name: "conv4_x__3_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__3_c1x1-a__ac__relu"
	top: "conv4_x__3_c1x1-a__conv"
	name: "conv4_x__3_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__3_c1x1-a__conv"
  top: "conv4_x__3_c3x3-b__bn__bn"
  name: "conv4_x__3_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__3_c3x3-b__bn__bn"
  top: "conv4_x__3_c3x3-b__bn__bn"
  name: "conv4_x__3_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__3_c3x3-b__bn__bn"
  top: "conv4_x__3_c3x3-b__ac__relu"
  name: "conv4_x__3_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__3_c3x3-b__ac__relu"
	top: "conv4_x__3_c3x3-b__conv"
	name: "conv4_x__3_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__3_c3x3-b__conv"
  top: "conv4_x__3_c1x1-c__bn__bn"
  name: "conv4_x__3_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__3_c1x1-c__bn__bn"
  top: "conv4_x__3_c1x1-c__bn__bn"
  name: "conv4_x__3_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__3_c1x1-c__bn__bn"
  top: "conv4_x__3_c1x1-c__ac__relu"
  name: "conv4_x__3_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__3_c1x1-c__ac__relu"
	top: "conv4_x__3_c1x1-c__conv"
	name: "conv4_x__3_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__3_c1x1-c-split1', 'name': 'conv4_x__3_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[256, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__3_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__3_sum"
  type: "Eltwise"
  bottom: "conv4_x__2_sum"
  bottom: "conv4_x__3_c1x1-c-split1"
  top: "conv4_x__3_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__3_c1x1-c-split2', 'name': 'conv4_x__3_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[256, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__3_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__3_cat"
  type: "Concat"
  bottom: "conv4_x__2_cat"
  bottom: "conv4_x__3_c1x1-c-split2"
  top: "conv4_x__3_cat"
}

layer {
  name: "conv4_x__4_cat-input"
  type: "Concat"
  bottom: "conv4_x__3_sum"
  bottom: "conv4_x__3_cat"
  top: "conv4_x__4_cat-input"
}

layer {
  bottom: "conv4_x__4_cat-input"
  top: "conv4_x__4_c1x1-a__bn__bn"
  name: "conv4_x__4_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__4_c1x1-a__bn__bn"
  top: "conv4_x__4_c1x1-a__bn__bn"
  name: "conv4_x__4_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__4_c1x1-a__bn__bn"
  top: "conv4_x__4_c1x1-a__ac__relu"
  name: "conv4_x__4_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__4_c1x1-a__ac__relu"
	top: "conv4_x__4_c1x1-a__conv"
	name: "conv4_x__4_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__4_c1x1-a__conv"
  top: "conv4_x__4_c3x3-b__bn__bn"
  name: "conv4_x__4_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__4_c3x3-b__bn__bn"
  top: "conv4_x__4_c3x3-b__bn__bn"
  name: "conv4_x__4_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__4_c3x3-b__bn__bn"
  top: "conv4_x__4_c3x3-b__ac__relu"
  name: "conv4_x__4_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__4_c3x3-b__ac__relu"
	top: "conv4_x__4_c3x3-b__conv"
	name: "conv4_x__4_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__4_c3x3-b__conv"
  top: "conv4_x__4_c1x1-c__bn__bn"
  name: "conv4_x__4_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__4_c1x1-c__bn__bn"
  top: "conv4_x__4_c1x1-c__bn__bn"
  name: "conv4_x__4_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__4_c1x1-c__bn__bn"
  top: "conv4_x__4_c1x1-c__ac__relu"
  name: "conv4_x__4_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__4_c1x1-c__ac__relu"
	top: "conv4_x__4_c1x1-c__conv"
	name: "conv4_x__4_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__4_c1x1-c-split1', 'name': 'conv4_x__4_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[279, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__4_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__4_sum"
  type: "Eltwise"
  bottom: "conv4_x__3_sum"
  bottom: "conv4_x__4_c1x1-c-split1"
  top: "conv4_x__4_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__4_c1x1-c-split2', 'name': 'conv4_x__4_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[279, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__4_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__4_cat"
  type: "Concat"
  bottom: "conv4_x__3_cat"
  bottom: "conv4_x__4_c1x1-c-split2"
  top: "conv4_x__4_cat"
}

layer {
  name: "conv4_x__5_cat-input"
  type: "Concat"
  bottom: "conv4_x__4_sum"
  bottom: "conv4_x__4_cat"
  top: "conv4_x__5_cat-input"
}

layer {
  bottom: "conv4_x__5_cat-input"
  top: "conv4_x__5_c1x1-a__bn__bn"
  name: "conv4_x__5_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__5_c1x1-a__bn__bn"
  top: "conv4_x__5_c1x1-a__bn__bn"
  name: "conv4_x__5_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__5_c1x1-a__bn__bn"
  top: "conv4_x__5_c1x1-a__ac__relu"
  name: "conv4_x__5_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__5_c1x1-a__ac__relu"
	top: "conv4_x__5_c1x1-a__conv"
	name: "conv4_x__5_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__5_c1x1-a__conv"
  top: "conv4_x__5_c3x3-b__bn__bn"
  name: "conv4_x__5_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__5_c3x3-b__bn__bn"
  top: "conv4_x__5_c3x3-b__bn__bn"
  name: "conv4_x__5_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__5_c3x3-b__bn__bn"
  top: "conv4_x__5_c3x3-b__ac__relu"
  name: "conv4_x__5_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__5_c3x3-b__ac__relu"
	top: "conv4_x__5_c3x3-b__conv"
	name: "conv4_x__5_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__5_c3x3-b__conv"
  top: "conv4_x__5_c1x1-c__bn__bn"
  name: "conv4_x__5_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__5_c1x1-c__bn__bn"
  top: "conv4_x__5_c1x1-c__bn__bn"
  name: "conv4_x__5_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__5_c1x1-c__bn__bn"
  top: "conv4_x__5_c1x1-c__ac__relu"
  name: "conv4_x__5_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__5_c1x1-c__ac__relu"
	top: "conv4_x__5_c1x1-c__conv"
	name: "conv4_x__5_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__5_c1x1-c-split1', 'name': 'conv4_x__5_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[302, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__5_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__5_sum"
  type: "Eltwise"
  bottom: "conv4_x__4_sum"
  bottom: "conv4_x__5_c1x1-c-split1"
  top: "conv4_x__5_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__5_c1x1-c-split2', 'name': 'conv4_x__5_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[302, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__5_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__5_cat"
  type: "Concat"
  bottom: "conv4_x__4_cat"
  bottom: "conv4_x__5_c1x1-c-split2"
  top: "conv4_x__5_cat"
}

layer {
  name: "conv4_x__6_cat-input"
  type: "Concat"
  bottom: "conv4_x__5_sum"
  bottom: "conv4_x__5_cat"
  top: "conv4_x__6_cat-input"
}

layer {
  bottom: "conv4_x__6_cat-input"
  top: "conv4_x__6_c1x1-a__bn__bn"
  name: "conv4_x__6_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__6_c1x1-a__bn__bn"
  top: "conv4_x__6_c1x1-a__bn__bn"
  name: "conv4_x__6_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__6_c1x1-a__bn__bn"
  top: "conv4_x__6_c1x1-a__ac__relu"
  name: "conv4_x__6_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__6_c1x1-a__ac__relu"
	top: "conv4_x__6_c1x1-a__conv"
	name: "conv4_x__6_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__6_c1x1-a__conv"
  top: "conv4_x__6_c3x3-b__bn__bn"
  name: "conv4_x__6_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__6_c3x3-b__bn__bn"
  top: "conv4_x__6_c3x3-b__bn__bn"
  name: "conv4_x__6_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__6_c3x3-b__bn__bn"
  top: "conv4_x__6_c3x3-b__ac__relu"
  name: "conv4_x__6_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__6_c3x3-b__ac__relu"
	top: "conv4_x__6_c3x3-b__conv"
	name: "conv4_x__6_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__6_c3x3-b__conv"
  top: "conv4_x__6_c1x1-c__bn__bn"
  name: "conv4_x__6_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__6_c1x1-c__bn__bn"
  top: "conv4_x__6_c1x1-c__bn__bn"
  name: "conv4_x__6_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__6_c1x1-c__bn__bn"
  top: "conv4_x__6_c1x1-c__ac__relu"
  name: "conv4_x__6_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__6_c1x1-c__ac__relu"
	top: "conv4_x__6_c1x1-c__conv"
	name: "conv4_x__6_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__6_c1x1-c-split1', 'name': 'conv4_x__6_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[325, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__6_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__6_sum"
  type: "Eltwise"
  bottom: "conv4_x__5_sum"
  bottom: "conv4_x__6_c1x1-c-split1"
  top: "conv4_x__6_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__6_c1x1-c-split2', 'name': 'conv4_x__6_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[325, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__6_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__6_cat"
  type: "Concat"
  bottom: "conv4_x__5_cat"
  bottom: "conv4_x__6_c1x1-c-split2"
  top: "conv4_x__6_cat"
}

layer {
  name: "conv4_x__7_cat-input"
  type: "Concat"
  bottom: "conv4_x__6_sum"
  bottom: "conv4_x__6_cat"
  top: "conv4_x__7_cat-input"
}

layer {
  bottom: "conv4_x__7_cat-input"
  top: "conv4_x__7_c1x1-a__bn__bn"
  name: "conv4_x__7_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__7_c1x1-a__bn__bn"
  top: "conv4_x__7_c1x1-a__bn__bn"
  name: "conv4_x__7_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__7_c1x1-a__bn__bn"
  top: "conv4_x__7_c1x1-a__ac__relu"
  name: "conv4_x__7_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__7_c1x1-a__ac__relu"
	top: "conv4_x__7_c1x1-a__conv"
	name: "conv4_x__7_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__7_c1x1-a__conv"
  top: "conv4_x__7_c3x3-b__bn__bn"
  name: "conv4_x__7_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__7_c3x3-b__bn__bn"
  top: "conv4_x__7_c3x3-b__bn__bn"
  name: "conv4_x__7_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__7_c3x3-b__bn__bn"
  top: "conv4_x__7_c3x3-b__ac__relu"
  name: "conv4_x__7_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__7_c3x3-b__ac__relu"
	top: "conv4_x__7_c3x3-b__conv"
	name: "conv4_x__7_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__7_c3x3-b__conv"
  top: "conv4_x__7_c1x1-c__bn__bn"
  name: "conv4_x__7_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__7_c1x1-c__bn__bn"
  top: "conv4_x__7_c1x1-c__bn__bn"
  name: "conv4_x__7_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__7_c1x1-c__bn__bn"
  top: "conv4_x__7_c1x1-c__ac__relu"
  name: "conv4_x__7_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__7_c1x1-c__ac__relu"
	top: "conv4_x__7_c1x1-c__conv"
	name: "conv4_x__7_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__7_c1x1-c-split1', 'name': 'conv4_x__7_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[348, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__7_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__7_sum"
  type: "Eltwise"
  bottom: "conv4_x__6_sum"
  bottom: "conv4_x__7_c1x1-c-split1"
  top: "conv4_x__7_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__7_c1x1-c-split2', 'name': 'conv4_x__7_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[348, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__7_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__7_cat"
  type: "Concat"
  bottom: "conv4_x__6_cat"
  bottom: "conv4_x__7_c1x1-c-split2"
  top: "conv4_x__7_cat"
}

layer {
  name: "conv4_x__8_cat-input"
  type: "Concat"
  bottom: "conv4_x__7_sum"
  bottom: "conv4_x__7_cat"
  top: "conv4_x__8_cat-input"
}

layer {
  bottom: "conv4_x__8_cat-input"
  top: "conv4_x__8_c1x1-a__bn__bn"
  name: "conv4_x__8_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__8_c1x1-a__bn__bn"
  top: "conv4_x__8_c1x1-a__bn__bn"
  name: "conv4_x__8_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__8_c1x1-a__bn__bn"
  top: "conv4_x__8_c1x1-a__ac__relu"
  name: "conv4_x__8_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__8_c1x1-a__ac__relu"
	top: "conv4_x__8_c1x1-a__conv"
	name: "conv4_x__8_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__8_c1x1-a__conv"
  top: "conv4_x__8_c3x3-b__bn__bn"
  name: "conv4_x__8_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__8_c3x3-b__bn__bn"
  top: "conv4_x__8_c3x3-b__bn__bn"
  name: "conv4_x__8_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__8_c3x3-b__bn__bn"
  top: "conv4_x__8_c3x3-b__ac__relu"
  name: "conv4_x__8_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__8_c3x3-b__ac__relu"
	top: "conv4_x__8_c3x3-b__conv"
	name: "conv4_x__8_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__8_c3x3-b__conv"
  top: "conv4_x__8_c1x1-c__bn__bn"
  name: "conv4_x__8_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__8_c1x1-c__bn__bn"
  top: "conv4_x__8_c1x1-c__bn__bn"
  name: "conv4_x__8_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__8_c1x1-c__bn__bn"
  top: "conv4_x__8_c1x1-c__ac__relu"
  name: "conv4_x__8_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__8_c1x1-c__ac__relu"
	top: "conv4_x__8_c1x1-c__conv"
	name: "conv4_x__8_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__8_c1x1-c-split1', 'name': 'conv4_x__8_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[371, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__8_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__8_sum"
  type: "Eltwise"
  bottom: "conv4_x__7_sum"
  bottom: "conv4_x__8_c1x1-c-split1"
  top: "conv4_x__8_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__8_c1x1-c-split2', 'name': 'conv4_x__8_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[371, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__8_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__8_cat"
  type: "Concat"
  bottom: "conv4_x__7_cat"
  bottom: "conv4_x__8_c1x1-c-split2"
  top: "conv4_x__8_cat"
}

layer {
  name: "conv4_x__9_cat-input"
  type: "Concat"
  bottom: "conv4_x__8_sum"
  bottom: "conv4_x__8_cat"
  top: "conv4_x__9_cat-input"
}

layer {
  bottom: "conv4_x__9_cat-input"
  top: "conv4_x__9_c1x1-a__bn__bn"
  name: "conv4_x__9_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__9_c1x1-a__bn__bn"
  top: "conv4_x__9_c1x1-a__bn__bn"
  name: "conv4_x__9_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__9_c1x1-a__bn__bn"
  top: "conv4_x__9_c1x1-a__ac__relu"
  name: "conv4_x__9_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__9_c1x1-a__ac__relu"
	top: "conv4_x__9_c1x1-a__conv"
	name: "conv4_x__9_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__9_c1x1-a__conv"
  top: "conv4_x__9_c3x3-b__bn__bn"
  name: "conv4_x__9_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__9_c3x3-b__bn__bn"
  top: "conv4_x__9_c3x3-b__bn__bn"
  name: "conv4_x__9_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__9_c3x3-b__bn__bn"
  top: "conv4_x__9_c3x3-b__ac__relu"
  name: "conv4_x__9_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__9_c3x3-b__ac__relu"
	top: "conv4_x__9_c3x3-b__conv"
	name: "conv4_x__9_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__9_c3x3-b__conv"
  top: "conv4_x__9_c1x1-c__bn__bn"
  name: "conv4_x__9_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__9_c1x1-c__bn__bn"
  top: "conv4_x__9_c1x1-c__bn__bn"
  name: "conv4_x__9_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__9_c1x1-c__bn__bn"
  top: "conv4_x__9_c1x1-c__ac__relu"
  name: "conv4_x__9_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__9_c1x1-c__ac__relu"
	top: "conv4_x__9_c1x1-c__conv"
	name: "conv4_x__9_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__9_c1x1-c-split1', 'name': 'conv4_x__9_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[394, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__9_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__9_sum"
  type: "Eltwise"
  bottom: "conv4_x__8_sum"
  bottom: "conv4_x__9_c1x1-c-split1"
  top: "conv4_x__9_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__9_c1x1-c-split2', 'name': 'conv4_x__9_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[394, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__9_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__9_cat"
  type: "Concat"
  bottom: "conv4_x__8_cat"
  bottom: "conv4_x__9_c1x1-c-split2"
  top: "conv4_x__9_cat"
}

layer {
  name: "conv4_x__10_cat-input"
  type: "Concat"
  bottom: "conv4_x__9_sum"
  bottom: "conv4_x__9_cat"
  top: "conv4_x__10_cat-input"
}

layer {
  bottom: "conv4_x__10_cat-input"
  top: "conv4_x__10_c1x1-a__bn__bn"
  name: "conv4_x__10_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__10_c1x1-a__bn__bn"
  top: "conv4_x__10_c1x1-a__bn__bn"
  name: "conv4_x__10_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__10_c1x1-a__bn__bn"
  top: "conv4_x__10_c1x1-a__ac__relu"
  name: "conv4_x__10_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__10_c1x1-a__ac__relu"
	top: "conv4_x__10_c1x1-a__conv"
	name: "conv4_x__10_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__10_c1x1-a__conv"
  top: "conv4_x__10_c3x3-b__bn__bn"
  name: "conv4_x__10_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__10_c3x3-b__bn__bn"
  top: "conv4_x__10_c3x3-b__bn__bn"
  name: "conv4_x__10_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__10_c3x3-b__bn__bn"
  top: "conv4_x__10_c3x3-b__ac__relu"
  name: "conv4_x__10_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__10_c3x3-b__ac__relu"
	top: "conv4_x__10_c3x3-b__conv"
	name: "conv4_x__10_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__10_c3x3-b__conv"
  top: "conv4_x__10_c1x1-c__bn__bn"
  name: "conv4_x__10_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__10_c1x1-c__bn__bn"
  top: "conv4_x__10_c1x1-c__bn__bn"
  name: "conv4_x__10_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__10_c1x1-c__bn__bn"
  top: "conv4_x__10_c1x1-c__ac__relu"
  name: "conv4_x__10_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__10_c1x1-c__ac__relu"
	top: "conv4_x__10_c1x1-c__conv"
	name: "conv4_x__10_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__10_c1x1-c-split1', 'name': 'conv4_x__10_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[417, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__10_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__10_sum"
  type: "Eltwise"
  bottom: "conv4_x__9_sum"
  bottom: "conv4_x__10_c1x1-c-split1"
  top: "conv4_x__10_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__10_c1x1-c-split2', 'name': 'conv4_x__10_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[417, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__10_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__10_cat"
  type: "Concat"
  bottom: "conv4_x__9_cat"
  bottom: "conv4_x__10_c1x1-c-split2"
  top: "conv4_x__10_cat"
}

layer {
  name: "conv4_x__11_cat-input"
  type: "Concat"
  bottom: "conv4_x__10_sum"
  bottom: "conv4_x__10_cat"
  top: "conv4_x__11_cat-input"
}

layer {
  bottom: "conv4_x__11_cat-input"
  top: "conv4_x__11_c1x1-a__bn__bn"
  name: "conv4_x__11_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__11_c1x1-a__bn__bn"
  top: "conv4_x__11_c1x1-a__bn__bn"
  name: "conv4_x__11_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__11_c1x1-a__bn__bn"
  top: "conv4_x__11_c1x1-a__ac__relu"
  name: "conv4_x__11_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__11_c1x1-a__ac__relu"
	top: "conv4_x__11_c1x1-a__conv"
	name: "conv4_x__11_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__11_c1x1-a__conv"
  top: "conv4_x__11_c3x3-b__bn__bn"
  name: "conv4_x__11_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__11_c3x3-b__bn__bn"
  top: "conv4_x__11_c3x3-b__bn__bn"
  name: "conv4_x__11_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__11_c3x3-b__bn__bn"
  top: "conv4_x__11_c3x3-b__ac__relu"
  name: "conv4_x__11_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__11_c3x3-b__ac__relu"
	top: "conv4_x__11_c3x3-b__conv"
	name: "conv4_x__11_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__11_c3x3-b__conv"
  top: "conv4_x__11_c1x1-c__bn__bn"
  name: "conv4_x__11_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__11_c1x1-c__bn__bn"
  top: "conv4_x__11_c1x1-c__bn__bn"
  name: "conv4_x__11_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__11_c1x1-c__bn__bn"
  top: "conv4_x__11_c1x1-c__ac__relu"
  name: "conv4_x__11_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__11_c1x1-c__ac__relu"
	top: "conv4_x__11_c1x1-c__conv"
	name: "conv4_x__11_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__11_c1x1-c-split1', 'name': 'conv4_x__11_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[440, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__11_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__11_sum"
  type: "Eltwise"
  bottom: "conv4_x__10_sum"
  bottom: "conv4_x__11_c1x1-c-split1"
  top: "conv4_x__11_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__11_c1x1-c-split2', 'name': 'conv4_x__11_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[440, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__11_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__11_cat"
  type: "Concat"
  bottom: "conv4_x__10_cat"
  bottom: "conv4_x__11_c1x1-c-split2"
  top: "conv4_x__11_cat"
}

layer {
  name: "conv4_x__12_cat-input"
  type: "Concat"
  bottom: "conv4_x__11_sum"
  bottom: "conv4_x__11_cat"
  top: "conv4_x__12_cat-input"
}

layer {
  bottom: "conv4_x__12_cat-input"
  top: "conv4_x__12_c1x1-a__bn__bn"
  name: "conv4_x__12_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__12_c1x1-a__bn__bn"
  top: "conv4_x__12_c1x1-a__bn__bn"
  name: "conv4_x__12_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__12_c1x1-a__bn__bn"
  top: "conv4_x__12_c1x1-a__ac__relu"
  name: "conv4_x__12_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__12_c1x1-a__ac__relu"
	top: "conv4_x__12_c1x1-a__conv"
	name: "conv4_x__12_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__12_c1x1-a__conv"
  top: "conv4_x__12_c3x3-b__bn__bn"
  name: "conv4_x__12_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__12_c3x3-b__bn__bn"
  top: "conv4_x__12_c3x3-b__bn__bn"
  name: "conv4_x__12_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__12_c3x3-b__bn__bn"
  top: "conv4_x__12_c3x3-b__ac__relu"
  name: "conv4_x__12_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__12_c3x3-b__ac__relu"
	top: "conv4_x__12_c3x3-b__conv"
	name: "conv4_x__12_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__12_c3x3-b__conv"
  top: "conv4_x__12_c1x1-c__bn__bn"
  name: "conv4_x__12_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__12_c1x1-c__bn__bn"
  top: "conv4_x__12_c1x1-c__bn__bn"
  name: "conv4_x__12_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__12_c1x1-c__bn__bn"
  top: "conv4_x__12_c1x1-c__ac__relu"
  name: "conv4_x__12_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__12_c1x1-c__ac__relu"
	top: "conv4_x__12_c1x1-c__conv"
	name: "conv4_x__12_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__12_c1x1-c-split1', 'name': 'conv4_x__12_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[463, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__12_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__12_sum"
  type: "Eltwise"
  bottom: "conv4_x__11_sum"
  bottom: "conv4_x__12_c1x1-c-split1"
  top: "conv4_x__12_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__12_c1x1-c-split2', 'name': 'conv4_x__12_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[463, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__12_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__12_cat"
  type: "Concat"
  bottom: "conv4_x__11_cat"
  bottom: "conv4_x__12_c1x1-c-split2"
  top: "conv4_x__12_cat"
}

layer {
  name: "conv4_x__13_cat-input"
  type: "Concat"
  bottom: "conv4_x__12_sum"
  bottom: "conv4_x__12_cat"
  top: "conv4_x__13_cat-input"
}

layer {
  bottom: "conv4_x__13_cat-input"
  top: "conv4_x__13_c1x1-a__bn__bn"
  name: "conv4_x__13_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__13_c1x1-a__bn__bn"
  top: "conv4_x__13_c1x1-a__bn__bn"
  name: "conv4_x__13_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__13_c1x1-a__bn__bn"
  top: "conv4_x__13_c1x1-a__ac__relu"
  name: "conv4_x__13_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__13_c1x1-a__ac__relu"
	top: "conv4_x__13_c1x1-a__conv"
	name: "conv4_x__13_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__13_c1x1-a__conv"
  top: "conv4_x__13_c3x3-b__bn__bn"
  name: "conv4_x__13_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__13_c3x3-b__bn__bn"
  top: "conv4_x__13_c3x3-b__bn__bn"
  name: "conv4_x__13_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__13_c3x3-b__bn__bn"
  top: "conv4_x__13_c3x3-b__ac__relu"
  name: "conv4_x__13_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__13_c3x3-b__ac__relu"
	top: "conv4_x__13_c3x3-b__conv"
	name: "conv4_x__13_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__13_c3x3-b__conv"
  top: "conv4_x__13_c1x1-c__bn__bn"
  name: "conv4_x__13_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__13_c1x1-c__bn__bn"
  top: "conv4_x__13_c1x1-c__bn__bn"
  name: "conv4_x__13_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__13_c1x1-c__bn__bn"
  top: "conv4_x__13_c1x1-c__ac__relu"
  name: "conv4_x__13_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__13_c1x1-c__ac__relu"
	top: "conv4_x__13_c1x1-c__conv"
	name: "conv4_x__13_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__13_c1x1-c-split1', 'name': 'conv4_x__13_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[486, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__13_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__13_sum"
  type: "Eltwise"
  bottom: "conv4_x__12_sum"
  bottom: "conv4_x__13_c1x1-c-split1"
  top: "conv4_x__13_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__13_c1x1-c-split2', 'name': 'conv4_x__13_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[486, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__13_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__13_cat"
  type: "Concat"
  bottom: "conv4_x__12_cat"
  bottom: "conv4_x__13_c1x1-c-split2"
  top: "conv4_x__13_cat"
}

layer {
  name: "conv4_x__14_cat-input"
  type: "Concat"
  bottom: "conv4_x__13_sum"
  bottom: "conv4_x__13_cat"
  top: "conv4_x__14_cat-input"
}

layer {
  bottom: "conv4_x__14_cat-input"
  top: "conv4_x__14_c1x1-a__bn__bn"
  name: "conv4_x__14_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__14_c1x1-a__bn__bn"
  top: "conv4_x__14_c1x1-a__bn__bn"
  name: "conv4_x__14_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__14_c1x1-a__bn__bn"
  top: "conv4_x__14_c1x1-a__ac__relu"
  name: "conv4_x__14_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__14_c1x1-a__ac__relu"
	top: "conv4_x__14_c1x1-a__conv"
	name: "conv4_x__14_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__14_c1x1-a__conv"
  top: "conv4_x__14_c3x3-b__bn__bn"
  name: "conv4_x__14_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__14_c3x3-b__bn__bn"
  top: "conv4_x__14_c3x3-b__bn__bn"
  name: "conv4_x__14_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__14_c3x3-b__bn__bn"
  top: "conv4_x__14_c3x3-b__ac__relu"
  name: "conv4_x__14_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__14_c3x3-b__ac__relu"
	top: "conv4_x__14_c3x3-b__conv"
	name: "conv4_x__14_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__14_c3x3-b__conv"
  top: "conv4_x__14_c1x1-c__bn__bn"
  name: "conv4_x__14_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__14_c1x1-c__bn__bn"
  top: "conv4_x__14_c1x1-c__bn__bn"
  name: "conv4_x__14_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__14_c1x1-c__bn__bn"
  top: "conv4_x__14_c1x1-c__ac__relu"
  name: "conv4_x__14_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__14_c1x1-c__ac__relu"
	top: "conv4_x__14_c1x1-c__conv"
	name: "conv4_x__14_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__14_c1x1-c-split1', 'name': 'conv4_x__14_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[509, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__14_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__14_sum"
  type: "Eltwise"
  bottom: "conv4_x__13_sum"
  bottom: "conv4_x__14_c1x1-c-split1"
  top: "conv4_x__14_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__14_c1x1-c-split2', 'name': 'conv4_x__14_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[509, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__14_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__14_cat"
  type: "Concat"
  bottom: "conv4_x__13_cat"
  bottom: "conv4_x__14_c1x1-c-split2"
  top: "conv4_x__14_cat"
}

layer {
  name: "conv4_x__15_cat-input"
  type: "Concat"
  bottom: "conv4_x__14_sum"
  bottom: "conv4_x__14_cat"
  top: "conv4_x__15_cat-input"
}

layer {
  bottom: "conv4_x__15_cat-input"
  top: "conv4_x__15_c1x1-a__bn__bn"
  name: "conv4_x__15_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__15_c1x1-a__bn__bn"
  top: "conv4_x__15_c1x1-a__bn__bn"
  name: "conv4_x__15_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__15_c1x1-a__bn__bn"
  top: "conv4_x__15_c1x1-a__ac__relu"
  name: "conv4_x__15_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__15_c1x1-a__ac__relu"
	top: "conv4_x__15_c1x1-a__conv"
	name: "conv4_x__15_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__15_c1x1-a__conv"
  top: "conv4_x__15_c3x3-b__bn__bn"
  name: "conv4_x__15_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__15_c3x3-b__bn__bn"
  top: "conv4_x__15_c3x3-b__bn__bn"
  name: "conv4_x__15_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__15_c3x3-b__bn__bn"
  top: "conv4_x__15_c3x3-b__ac__relu"
  name: "conv4_x__15_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__15_c3x3-b__ac__relu"
	top: "conv4_x__15_c3x3-b__conv"
	name: "conv4_x__15_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__15_c3x3-b__conv"
  top: "conv4_x__15_c1x1-c__bn__bn"
  name: "conv4_x__15_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__15_c1x1-c__bn__bn"
  top: "conv4_x__15_c1x1-c__bn__bn"
  name: "conv4_x__15_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__15_c1x1-c__bn__bn"
  top: "conv4_x__15_c1x1-c__ac__relu"
  name: "conv4_x__15_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__15_c1x1-c__ac__relu"
	top: "conv4_x__15_c1x1-c__conv"
	name: "conv4_x__15_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__15_c1x1-c-split1', 'name': 'conv4_x__15_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[532, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__15_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__15_sum"
  type: "Eltwise"
  bottom: "conv4_x__14_sum"
  bottom: "conv4_x__15_c1x1-c-split1"
  top: "conv4_x__15_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__15_c1x1-c-split2', 'name': 'conv4_x__15_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[532, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__15_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__15_cat"
  type: "Concat"
  bottom: "conv4_x__14_cat"
  bottom: "conv4_x__15_c1x1-c-split2"
  top: "conv4_x__15_cat"
}

layer {
  name: "conv4_x__16_cat-input"
  type: "Concat"
  bottom: "conv4_x__15_sum"
  bottom: "conv4_x__15_cat"
  top: "conv4_x__16_cat-input"
}

layer {
  bottom: "conv4_x__16_cat-input"
  top: "conv4_x__16_c1x1-a__bn__bn"
  name: "conv4_x__16_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__16_c1x1-a__bn__bn"
  top: "conv4_x__16_c1x1-a__bn__bn"
  name: "conv4_x__16_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__16_c1x1-a__bn__bn"
  top: "conv4_x__16_c1x1-a__ac__relu"
  name: "conv4_x__16_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__16_c1x1-a__ac__relu"
	top: "conv4_x__16_c1x1-a__conv"
	name: "conv4_x__16_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__16_c1x1-a__conv"
  top: "conv4_x__16_c3x3-b__bn__bn"
  name: "conv4_x__16_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__16_c3x3-b__bn__bn"
  top: "conv4_x__16_c3x3-b__bn__bn"
  name: "conv4_x__16_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__16_c3x3-b__bn__bn"
  top: "conv4_x__16_c3x3-b__ac__relu"
  name: "conv4_x__16_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__16_c3x3-b__ac__relu"
	top: "conv4_x__16_c3x3-b__conv"
	name: "conv4_x__16_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__16_c3x3-b__conv"
  top: "conv4_x__16_c1x1-c__bn__bn"
  name: "conv4_x__16_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__16_c1x1-c__bn__bn"
  top: "conv4_x__16_c1x1-c__bn__bn"
  name: "conv4_x__16_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__16_c1x1-c__bn__bn"
  top: "conv4_x__16_c1x1-c__ac__relu"
  name: "conv4_x__16_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__16_c1x1-c__ac__relu"
	top: "conv4_x__16_c1x1-c__conv"
	name: "conv4_x__16_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__16_c1x1-c-split1', 'name': 'conv4_x__16_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[555, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__16_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__16_sum"
  type: "Eltwise"
  bottom: "conv4_x__15_sum"
  bottom: "conv4_x__16_c1x1-c-split1"
  top: "conv4_x__16_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__16_c1x1-c-split2', 'name': 'conv4_x__16_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[555, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__16_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__16_cat"
  type: "Concat"
  bottom: "conv4_x__15_cat"
  bottom: "conv4_x__16_c1x1-c-split2"
  top: "conv4_x__16_cat"
}

layer {
  name: "conv4_x__17_cat-input"
  type: "Concat"
  bottom: "conv4_x__16_sum"
  bottom: "conv4_x__16_cat"
  top: "conv4_x__17_cat-input"
}

layer {
  bottom: "conv4_x__17_cat-input"
  top: "conv4_x__17_c1x1-a__bn__bn"
  name: "conv4_x__17_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__17_c1x1-a__bn__bn"
  top: "conv4_x__17_c1x1-a__bn__bn"
  name: "conv4_x__17_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__17_c1x1-a__bn__bn"
  top: "conv4_x__17_c1x1-a__ac__relu"
  name: "conv4_x__17_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__17_c1x1-a__ac__relu"
	top: "conv4_x__17_c1x1-a__conv"
	name: "conv4_x__17_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__17_c1x1-a__conv"
  top: "conv4_x__17_c3x3-b__bn__bn"
  name: "conv4_x__17_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__17_c3x3-b__bn__bn"
  top: "conv4_x__17_c3x3-b__bn__bn"
  name: "conv4_x__17_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__17_c3x3-b__bn__bn"
  top: "conv4_x__17_c3x3-b__ac__relu"
  name: "conv4_x__17_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__17_c3x3-b__ac__relu"
	top: "conv4_x__17_c3x3-b__conv"
	name: "conv4_x__17_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__17_c3x3-b__conv"
  top: "conv4_x__17_c1x1-c__bn__bn"
  name: "conv4_x__17_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__17_c1x1-c__bn__bn"
  top: "conv4_x__17_c1x1-c__bn__bn"
  name: "conv4_x__17_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__17_c1x1-c__bn__bn"
  top: "conv4_x__17_c1x1-c__ac__relu"
  name: "conv4_x__17_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__17_c1x1-c__ac__relu"
	top: "conv4_x__17_c1x1-c__conv"
	name: "conv4_x__17_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__17_c1x1-c-split1', 'name': 'conv4_x__17_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[578, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__17_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__17_sum"
  type: "Eltwise"
  bottom: "conv4_x__16_sum"
  bottom: "conv4_x__17_c1x1-c-split1"
  top: "conv4_x__17_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__17_c1x1-c-split2', 'name': 'conv4_x__17_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[578, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__17_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__17_cat"
  type: "Concat"
  bottom: "conv4_x__16_cat"
  bottom: "conv4_x__17_c1x1-c-split2"
  top: "conv4_x__17_cat"
}

layer {
  name: "conv4_x__18_cat-input"
  type: "Concat"
  bottom: "conv4_x__17_sum"
  bottom: "conv4_x__17_cat"
  top: "conv4_x__18_cat-input"
}

layer {
  bottom: "conv4_x__18_cat-input"
  top: "conv4_x__18_c1x1-a__bn__bn"
  name: "conv4_x__18_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__18_c1x1-a__bn__bn"
  top: "conv4_x__18_c1x1-a__bn__bn"
  name: "conv4_x__18_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__18_c1x1-a__bn__bn"
  top: "conv4_x__18_c1x1-a__ac__relu"
  name: "conv4_x__18_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__18_c1x1-a__ac__relu"
	top: "conv4_x__18_c1x1-a__conv"
	name: "conv4_x__18_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__18_c1x1-a__conv"
  top: "conv4_x__18_c3x3-b__bn__bn"
  name: "conv4_x__18_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__18_c3x3-b__bn__bn"
  top: "conv4_x__18_c3x3-b__bn__bn"
  name: "conv4_x__18_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__18_c3x3-b__bn__bn"
  top: "conv4_x__18_c3x3-b__ac__relu"
  name: "conv4_x__18_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__18_c3x3-b__ac__relu"
	top: "conv4_x__18_c3x3-b__conv"
	name: "conv4_x__18_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__18_c3x3-b__conv"
  top: "conv4_x__18_c1x1-c__bn__bn"
  name: "conv4_x__18_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__18_c1x1-c__bn__bn"
  top: "conv4_x__18_c1x1-c__bn__bn"
  name: "conv4_x__18_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__18_c1x1-c__bn__bn"
  top: "conv4_x__18_c1x1-c__ac__relu"
  name: "conv4_x__18_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__18_c1x1-c__ac__relu"
	top: "conv4_x__18_c1x1-c__conv"
	name: "conv4_x__18_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__18_c1x1-c-split1', 'name': 'conv4_x__18_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[601, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__18_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__18_sum"
  type: "Eltwise"
  bottom: "conv4_x__17_sum"
  bottom: "conv4_x__18_c1x1-c-split1"
  top: "conv4_x__18_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__18_c1x1-c-split2', 'name': 'conv4_x__18_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[601, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__18_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__18_cat"
  type: "Concat"
  bottom: "conv4_x__17_cat"
  bottom: "conv4_x__18_c1x1-c-split2"
  top: "conv4_x__18_cat"
}

layer {
  name: "conv4_x__19_cat-input"
  type: "Concat"
  bottom: "conv4_x__18_sum"
  bottom: "conv4_x__18_cat"
  top: "conv4_x__19_cat-input"
}

layer {
  bottom: "conv4_x__19_cat-input"
  top: "conv4_x__19_c1x1-a__bn__bn"
  name: "conv4_x__19_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__19_c1x1-a__bn__bn"
  top: "conv4_x__19_c1x1-a__bn__bn"
  name: "conv4_x__19_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__19_c1x1-a__bn__bn"
  top: "conv4_x__19_c1x1-a__ac__relu"
  name: "conv4_x__19_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__19_c1x1-a__ac__relu"
	top: "conv4_x__19_c1x1-a__conv"
	name: "conv4_x__19_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__19_c1x1-a__conv"
  top: "conv4_x__19_c3x3-b__bn__bn"
  name: "conv4_x__19_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__19_c3x3-b__bn__bn"
  top: "conv4_x__19_c3x3-b__bn__bn"
  name: "conv4_x__19_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__19_c3x3-b__bn__bn"
  top: "conv4_x__19_c3x3-b__ac__relu"
  name: "conv4_x__19_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__19_c3x3-b__ac__relu"
	top: "conv4_x__19_c3x3-b__conv"
	name: "conv4_x__19_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__19_c3x3-b__conv"
  top: "conv4_x__19_c1x1-c__bn__bn"
  name: "conv4_x__19_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__19_c1x1-c__bn__bn"
  top: "conv4_x__19_c1x1-c__bn__bn"
  name: "conv4_x__19_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__19_c1x1-c__bn__bn"
  top: "conv4_x__19_c1x1-c__ac__relu"
  name: "conv4_x__19_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__19_c1x1-c__ac__relu"
	top: "conv4_x__19_c1x1-c__conv"
	name: "conv4_x__19_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__19_c1x1-c-split1', 'name': 'conv4_x__19_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[624, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__19_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__19_sum"
  type: "Eltwise"
  bottom: "conv4_x__18_sum"
  bottom: "conv4_x__19_c1x1-c-split1"
  top: "conv4_x__19_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__19_c1x1-c-split2', 'name': 'conv4_x__19_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[624, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__19_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__19_cat"
  type: "Concat"
  bottom: "conv4_x__18_cat"
  bottom: "conv4_x__19_c1x1-c-split2"
  top: "conv4_x__19_cat"
}

layer {
  name: "conv4_x__20_cat-input"
  type: "Concat"
  bottom: "conv4_x__19_sum"
  bottom: "conv4_x__19_cat"
  top: "conv4_x__20_cat-input"
}

layer {
  bottom: "conv4_x__20_cat-input"
  top: "conv4_x__20_c1x1-a__bn__bn"
  name: "conv4_x__20_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__20_c1x1-a__bn__bn"
  top: "conv4_x__20_c1x1-a__bn__bn"
  name: "conv4_x__20_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__20_c1x1-a__bn__bn"
  top: "conv4_x__20_c1x1-a__ac__relu"
  name: "conv4_x__20_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__20_c1x1-a__ac__relu"
	top: "conv4_x__20_c1x1-a__conv"
	name: "conv4_x__20_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__20_c1x1-a__conv"
  top: "conv4_x__20_c3x3-b__bn__bn"
  name: "conv4_x__20_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__20_c3x3-b__bn__bn"
  top: "conv4_x__20_c3x3-b__bn__bn"
  name: "conv4_x__20_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__20_c3x3-b__bn__bn"
  top: "conv4_x__20_c3x3-b__ac__relu"
  name: "conv4_x__20_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__20_c3x3-b__ac__relu"
	top: "conv4_x__20_c3x3-b__conv"
	name: "conv4_x__20_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv4_x__20_c3x3-b__conv"
  top: "conv4_x__20_c1x1-c__bn__bn"
  name: "conv4_x__20_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv4_x__20_c1x1-c__bn__bn"
  top: "conv4_x__20_c1x1-c__bn__bn"
  name: "conv4_x__20_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv4_x__20_c1x1-c__bn__bn"
  top: "conv4_x__20_c1x1-c__ac__relu"
  name: "conv4_x__20_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv4_x__20_c1x1-c__ac__relu"
	top: "conv4_x__20_c1x1-c__conv"
	name: "conv4_x__20_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 1048
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '1024', 'begin': '0'}, 'top': 'conv4_x__20_c1x1-c-split1', 'name': 'conv4_x__20_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[647, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__20_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__20_sum"
  type: "Eltwise"
  bottom: "conv4_x__19_sum"
  bottom: "conv4_x__20_c1x1-c-split1"
  top: "conv4_x__20_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '1048', 'begin': '1024'}, 'top': 'conv4_x__20_c1x1-c-split2', 'name': 'conv4_x__20_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[647, 0]], 'backward_source_id': -1, 'bottom': ['conv4_x__20_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv4_x__20_cat"
  type: "Concat"
  bottom: "conv4_x__19_cat"
  bottom: "conv4_x__20_c1x1-c-split2"
  top: "conv4_x__20_cat"
}

layer {
  name: "conv5_x__1_cat-input"
  type: "Concat"
  bottom: "conv4_x__20_sum"
  bottom: "conv4_x__20_cat"
  top: "conv5_x__1_cat-input"
}

layer {
  bottom: "conv5_x__1_cat-input"
  top: "conv5_x__1_c1x1-w(s/2)__bn__bn"
  name: "conv5_x__1_c1x1-w(s/2)__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv5_x__1_c1x1-w(s/2)__bn__bn"
  top: "conv5_x__1_c1x1-w(s/2)__bn__bn"
  name: "conv5_x__1_c1x1-w(s/2)__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv5_x__1_c1x1-w(s/2)__bn__bn"
  top: "conv5_x__1_c1x1-w(s/2)__ac__relu"
  name: "conv5_x__1_c1x1-w(s/2)__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv5_x__1_c1x1-w(s/2)__ac__relu"
	top: "conv5_x__1_c1x1-w(s/2)__conv"
	name: "conv5_x__1_c1x1-w(s/2)__conv"
	type: "Convolution"
	convolution_param {
		num_output: 2304
		kernel_size: 1
		pad: 0
		group: 1
		stride: 2
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '2048', 'begin': '0'}, 'top': 'conv5_x__1_c1x1-w(s/2)-split1', 'name': 'conv5_x__1_c1x1-w(s/2)-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[658, 0]], 'backward_source_id': -1, 'bottom': ['conv5_x__1_c1x1-w(s/2)__conv']}
</slice_json>
layer {
  bottom: "conv5_x__1_cat-input"
  top: "conv5_x__1_c1x1-a__bn__bn"
  name: "conv5_x__1_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv5_x__1_c1x1-a__bn__bn"
  top: "conv5_x__1_c1x1-a__bn__bn"
  name: "conv5_x__1_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv5_x__1_c1x1-a__bn__bn"
  top: "conv5_x__1_c1x1-a__ac__relu"
  name: "conv5_x__1_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv5_x__1_c1x1-a__ac__relu"
	top: "conv5_x__1_c1x1-a__conv"
	name: "conv5_x__1_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 768
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv5_x__1_c1x1-a__conv"
  top: "conv5_x__1_c3x3-b__bn__bn"
  name: "conv5_x__1_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv5_x__1_c3x3-b__bn__bn"
  top: "conv5_x__1_c3x3-b__bn__bn"
  name: "conv5_x__1_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv5_x__1_c3x3-b__bn__bn"
  top: "conv5_x__1_c3x3-b__ac__relu"
  name: "conv5_x__1_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv5_x__1_c3x3-b__ac__relu"
	top: "conv5_x__1_c3x3-b__conv"
	name: "conv5_x__1_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 768
		kernel_size: 3
		pad: 1
		group: 32
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "conv5_x__1_c3x3-b__conv"
  top: "conv5_x__1_c1x1-c__bn__bn"
  name: "conv5_x__1_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv5_x__1_c1x1-c__bn__bn"
  top: "conv5_x__1_c1x1-c__bn__bn"
  name: "conv5_x__1_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv5_x__1_c1x1-c__bn__bn"
  top: "conv5_x__1_c1x1-c__ac__relu"
  name: "conv5_x__1_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv5_x__1_c1x1-c__ac__relu"
	top: "conv5_x__1_c1x1-c__conv"
	name: "conv5_x__1_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 2176
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '2048', 'begin': '0'}, 'top': 'conv5_x__1_c1x1-c-split1', 'name': 'conv5_x__1_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[677, 0]], 'backward_source_id': -1, 'bottom': ['conv5_x__1_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv5_x__1_sum"
  type: "Eltwise"
  bottom: "conv5_x__1_c1x1-w(s/2)-split1"
  bottom: "conv5_x__1_c1x1-c-split1"
  top: "conv5_x__1_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '2304', 'begin': '2048'}, 'top': 'conv5_x__1_c1x1-w(s/2)-split2', 'name': 'conv5_x__1_c1x1-w(s/2)-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[658, 0]], 'backward_source_id': -1, 'bottom': ['conv5_x__1_c1x1-w(s/2)__conv']}
</slice_json>
<slice_json>
{'param': {'axis': '1', 'end': '2176', 'begin': '2048'}, 'top': 'conv5_x__1_c1x1-c-split2', 'name': 'conv5_x__1_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[677, 0]], 'backward_source_id': -1, 'bottom': ['conv5_x__1_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv5_x__1_cat"
  type: "Concat"
  bottom: "conv5_x__1_c1x1-w(s/2)-split2"
  bottom: "conv5_x__1_c1x1-c-split2"
  top: "conv5_x__1_cat"
}

layer {
  name: "conv5_x__2_cat-input"
  type: "Concat"
  bottom: "conv5_x__1_sum"
  bottom: "conv5_x__1_cat"
  top: "conv5_x__2_cat-input"
}

layer {
  bottom: "conv5_x__2_cat-input"
  top: "conv5_x__2_c1x1-a__bn__bn"
  name: "conv5_x__2_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv5_x__2_c1x1-a__bn__bn"
  top: "conv5_x__2_c1x1-a__bn__bn"
  name: "conv5_x__2_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv5_x__2_c1x1-a__bn__bn"
  top: "conv5_x__2_c1x1-a__ac__relu"
  name: "conv5_x__2_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv5_x__2_c1x1-a__ac__relu"
	top: "conv5_x__2_c1x1-a__conv"
	name: "conv5_x__2_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 768
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv5_x__2_c1x1-a__conv"
  top: "conv5_x__2_c3x3-b__bn__bn"
  name: "conv5_x__2_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv5_x__2_c3x3-b__bn__bn"
  top: "conv5_x__2_c3x3-b__bn__bn"
  name: "conv5_x__2_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv5_x__2_c3x3-b__bn__bn"
  top: "conv5_x__2_c3x3-b__ac__relu"
  name: "conv5_x__2_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv5_x__2_c3x3-b__ac__relu"
	top: "conv5_x__2_c3x3-b__conv"
	name: "conv5_x__2_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 768
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv5_x__2_c3x3-b__conv"
  top: "conv5_x__2_c1x1-c__bn__bn"
  name: "conv5_x__2_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv5_x__2_c1x1-c__bn__bn"
  top: "conv5_x__2_c1x1-c__bn__bn"
  name: "conv5_x__2_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv5_x__2_c1x1-c__bn__bn"
  top: "conv5_x__2_c1x1-c__ac__relu"
  name: "conv5_x__2_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv5_x__2_c1x1-c__ac__relu"
	top: "conv5_x__2_c1x1-c__conv"
	name: "conv5_x__2_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 2176
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '2048', 'begin': '0'}, 'top': 'conv5_x__2_c1x1-c-split1', 'name': 'conv5_x__2_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[701, 0]], 'backward_source_id': -1, 'bottom': ['conv5_x__2_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv5_x__2_sum"
  type: "Eltwise"
  bottom: "conv5_x__1_sum"
  bottom: "conv5_x__2_c1x1-c-split1"
  top: "conv5_x__2_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '2176', 'begin': '2048'}, 'top': 'conv5_x__2_c1x1-c-split2', 'name': 'conv5_x__2_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[701, 0]], 'backward_source_id': -1, 'bottom': ['conv5_x__2_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv5_x__2_cat"
  type: "Concat"
  bottom: "conv5_x__1_cat"
  bottom: "conv5_x__2_c1x1-c-split2"
  top: "conv5_x__2_cat"
}

layer {
  name: "conv5_x__3_cat-input"
  type: "Concat"
  bottom: "conv5_x__2_sum"
  bottom: "conv5_x__2_cat"
  top: "conv5_x__3_cat-input"
}

layer {
  bottom: "conv5_x__3_cat-input"
  top: "conv5_x__3_c1x1-a__bn__bn"
  name: "conv5_x__3_c1x1-a__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv5_x__3_c1x1-a__bn__bn"
  top: "conv5_x__3_c1x1-a__bn__bn"
  name: "conv5_x__3_c1x1-a__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv5_x__3_c1x1-a__bn__bn"
  top: "conv5_x__3_c1x1-a__ac__relu"
  name: "conv5_x__3_c1x1-a__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv5_x__3_c1x1-a__ac__relu"
	top: "conv5_x__3_c1x1-a__conv"
	name: "conv5_x__3_c1x1-a__conv"
	type: "Convolution"
	convolution_param {
		num_output: 768
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv5_x__3_c1x1-a__conv"
  top: "conv5_x__3_c3x3-b__bn__bn"
  name: "conv5_x__3_c3x3-b__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv5_x__3_c3x3-b__bn__bn"
  top: "conv5_x__3_c3x3-b__bn__bn"
  name: "conv5_x__3_c3x3-b__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv5_x__3_c3x3-b__bn__bn"
  top: "conv5_x__3_c3x3-b__ac__relu"
  name: "conv5_x__3_c3x3-b__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv5_x__3_c3x3-b__ac__relu"
	top: "conv5_x__3_c3x3-b__conv"
	name: "conv5_x__3_c3x3-b__conv"
	type: "Convolution"
	convolution_param {
		num_output: 768
		kernel_size: 3
		pad: 1
		group: 32
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv5_x__3_c3x3-b__conv"
  top: "conv5_x__3_c1x1-c__bn__bn"
  name: "conv5_x__3_c1x1-c__bn__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv5_x__3_c1x1-c__bn__bn"
  top: "conv5_x__3_c1x1-c__bn__bn"
  name: "conv5_x__3_c1x1-c__bn__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv5_x__3_c1x1-c__bn__bn"
  top: "conv5_x__3_c1x1-c__ac__relu"
  name: "conv5_x__3_c1x1-c__ac__relu"
  type: "ReLU"
}

layer {
	bottom: "conv5_x__3_c1x1-c__ac__relu"
	top: "conv5_x__3_c1x1-c__conv"
	name: "conv5_x__3_c1x1-c__conv"
	type: "Convolution"
	convolution_param {
		num_output: 2176
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

<slice_json>
{'param': {'axis': '1', 'end': '2048', 'begin': '0'}, 'top': 'conv5_x__3_c1x1-c-split1', 'name': 'conv5_x__3_c1x1-c-split1', 'params': [], 'op': 'slice_axis', 'inputs': [[724, 0]], 'backward_source_id': -1, 'bottom': ['conv5_x__3_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv5_x__3_sum"
  type: "Eltwise"
  bottom: "conv5_x__2_sum"
  bottom: "conv5_x__3_c1x1-c-split1"
  top: "conv5_x__3_sum"
}

<slice_json>
{'param': {'axis': '1', 'end': '2176', 'begin': '2048'}, 'top': 'conv5_x__3_c1x1-c-split2', 'name': 'conv5_x__3_c1x1-c-split2', 'params': [], 'op': 'slice_axis', 'inputs': [[724, 0]], 'backward_source_id': -1, 'bottom': ['conv5_x__3_c1x1-c__conv']}
</slice_json>
layer {
  name: "conv5_x__3_cat"
  type: "Concat"
  bottom: "conv5_x__2_cat"
  bottom: "conv5_x__3_c1x1-c-split2"
  top: "conv5_x__3_cat"
}

layer {
  name: "conv5_x_x_cat-final"
  type: "Concat"
  bottom: "conv5_x__3_sum"
  bottom: "conv5_x__3_cat"
  top: "conv5_x_x_cat-final"
}

layer {
  bottom: "conv5_x_x_cat-final"
  top: "conv5_x_x__relu-sp__bn"
  name: "conv5_x_x__relu-sp__bn"
  type: "BatchNorm"
}
layer {
  bottom: "conv5_x_x__relu-sp__bn"
  top: "conv5_x_x__relu-sp__bn"
  name: "conv5_x_x__relu-sp__bn_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "conv5_x_x__relu-sp__bn"
  top: "conv5_x_x__relu-sp__relu"
  name: "conv5_x_x__relu-sp__relu"
  type: "ReLU"
}

layer {
  bottom: "conv5_x_x__relu-sp__relu"
  top: "pool5"
  name: "pool5"
  type: "Pooling"
  pooling_param {
    pool: AVE
    kernel_size: 7
    stride: 1
    pad: 0
  }
}

layer {
  bottom: "pool5"
  top: "flatten"
  name: "flatten"
  type: "Flatten"
}

layer {
  bottom: "flatten"
  top: "fc6"
  name: "fc6"
  type: "InnerProduct"
  inner_product_param {
    num_output: 1000
  }
}

